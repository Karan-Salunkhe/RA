# Research Task 07 â€“ Final Integrated Report  
*By Karan Salunkhe*  

---

## ðŸ“‘ Table of Contents
1. [Introduction](#ðŸ“Œ-introduction)  
2. [Task 4 â€“ CSV Analyzer](#ðŸ”¹-task-4---csv-analyzer)  
   - [Objective](#objective)  
   - [Methodology](#methodology)  
   - [Why This Step Was Done](#why-this-step-was-done)  
   - [Summary of Task 4](#summary-of-task-4)  
3. [Task 5 â€“ Descriptive Statistics & LLM Validation](#ðŸ”¹-task-5---descriptive-statistics--llm-validation)  
   - [Objective](#objective-1)  
   - [Methodology](#methodology-1)  
   - [Key Results](#key-results)  
   - [Insights](#insights)  
   - [Why This Step Was Done](#why-this-step-was-done-1)  
   - [Summary of Task 5](#summary-of-task-5)  
4. [Task 6 â€“ Deep Fake Interview](#ðŸ”¹-task-6---deep-fake-interview)  
   - [Objective](#objective-2)  
   - [Methodology](#methodology-2)  
   - [Why This Step Was Done](#why-this-step-was-done-2)  
   - [Summary of Task 6](#summary-of-task-6)  
5. [Task 7 â€“ Integration and Final Reflection](#ðŸ”¹-task-7---integration-and-final-reflection)  
   - [Strengths Across Tasks](#strengths-across-tasks)  
   - [Challenges](#challenges)  
   - [Lessons Learned](#lessons-learned)  
   - [Practical Applications](#practical-applications)  
   - [Summary of Task 7](#summary-of-task-7)  
6. [Appendices](#ðŸ“‚-appendices)  
   - [Appendix A â€“ Key Task 4 Code Snippets](#appendix-a---key-task-4-code-snippets)  
   - [Appendix B â€“ Task 5 LLM Outputs vs Script](#appendix-b---task-5-llm-outputs-vs-script)  
   - [Appendix C â€“ Full Task 6 Interview Script](#appendix-c---full-task-6-interview-script)  
7. [Final Conclusion](#ðŸ“Š-final-conclusion)  

---

## ðŸ“Œ Introduction  

This report consolidates **Research Task 04, Task 05, and Task 06** into a single integrated deliverable. The goal of Task 07 is to demonstrate technical proficiency in scripting and data analysis, critical thinking, validation of AI outputs, and the ability to transform data into stakeholder-facing narratives.  

The sequence of tasks reflects a **real-world analytics pipeline**:  

1. **Task 4** â†’ Build a robust data analysis foundation (CSV Analyzer).  
2. **Task 5** â†’ Validate Large Language Model (LLM) responses against real IPL 2025 cricket data.  
3. **Task 6** â†’ Translate validated insights into a human-centered media-style narrative.  

By linking these stages, this report illustrates the journey from **raw data â†’ insights â†’ actionable communication**.  

---

## ðŸ”¹ Task 4 â€“ CSV Analyzer  

### Objective  
To design and implement a **Pandas-based CSV Analyzer** that can handle structured and semi-structured (JSON-like) CSV data, generate descriptive statistics, and allow optional aggregation.  

### Methodology  
- **Detection of JSON Columns** â†’ Scans columns using regex for `{}` patterns.  
- **Unpacking JSON Columns** â†’ Uses `ast.literal_eval` and `pd.json_normalize` to flatten nested structures.  
- **Numeric Summaries** â†’ Computes Count, Mean, Min, Max, StdDev.  
- **Text Summaries** â†’ Computes Count, Unique Values, Top Value & Frequency.  
- **Aggregation** â†’ Optionally group by categorical columns and compute mean of numeric columns.  

### Why This Step Was Done  
This step provided a **reusable foundation** for dataset analysis and ensured consistent, trustworthy statistics for subsequent LLM validation in Task 5.  

### Summary of Task 4  
Task 4 produced a **universal CSV analysis engine**, allowing IPL cricket data to be efficiently unpacked, summarized, and grouped. This ensured reliability for future AI validation and narrative construction.  

---

## ðŸ”¹ Task 5 â€“ Descriptive Statistics & LLM Validation  

### Objective  
To evaluate the accuracy of ChatGPT and DeepSeek when answering natural language queries about the **IPL 2025 cricket dataset**, and to validate outputs against the Pandas script from Task 4.  

### Methodology  
1. **Dataset** â†’ IPL 2025 season: batting and bowling statistics.  
2. **Question Design** â†’ Natural language queries (Q1â€“Q6).  
3. **LLM Comparison** â†’ Responses generated by ChatGPT and DeepSeek.  
4. **Validation** â†’ Numeric outputs validated using Pandas script.  
5. **Documentation** â†’ Comparison tables and detailed records of outputs.  

### Key Results  

| Q# | Question | ChatGPT Answer | DeepSeek Answer | Script Answer |
|----|-----------|----------------|-----------------|---------------|
| 1 | Highest strike rate (>500 runs) | Nicholas Pooran â€“ SR 196.2, Runs 524 | Nicholas Pooran â€“ SR 196.25, Runs 524 | **196.25** |
| 2 | Kohli vs Bumrah contributions | Kohli (with narrative) | Kohli (657 > 293.3) | **657 / 293.3** |
| 3 | Most overs bowled | Siraj â€“ 57 overs (342 balls) | Siraj â€“ 57 overs | **57** |
| 4 | Team-building under pressure | Pooran + Bumrah | Hardik Pandya | N/A |
| 5 | Playoff picks | Pooran, SKY, Iyer, Sudharsan, Klaasen + Noor, Bumrah, Hazlewood | Pooran, Gill, Iyer, Klaasen, SKY + Bumrah, Rashid, Noor | N/A |
| 6 | Young bowler with potential | Noor Ahmad â€“ 24 wickets, SR 12.5 | Noor Ahmad â€“ 24 wickets, SR 12.5 | **24 / 12.5** |

### Insights  
- Numeric outputs match script-validated results; interpretive answers diverge.  
- Pandas validation ensured **trustworthiness**.  
- LLMs are **accurate for descriptive stats**, less consistent on judgment calls.  

### Why This Step Was Done  
To **stress-test LLMs against a trusted pipeline** and demonstrate the need for validation when producing actionable insights.  

### Summary of Task 5  
LLMs are reliable for numeric queries, but Pandas validation is critical for interpretive claims. Task 5 highlights **the importance of combining AI reasoning with verified data**.  

---

## ðŸ”¹ Task 6 â€“ Deep Fake Interview  

### Objective  
To convert Task 5 insights into a **stakeholder-facing narrative** using a simulated post-season media interview with Sachin Tendulkar.  

### Methodology  
1. Draft interview script using key statistics from Task 5.  
2. Test AI video tools: D-ID, HeyGen, CapCut, Canva.  
3. Use **Descript** for final video: assign AI voices, align dialogue, export `.mp4`.  

### Why This Step Was Done  
Task 6 demonstrates **how validated insights can be transformed into engaging narratives** for stakeholders, media, and fans.  

### Summary of Task 6  
Task 6 produced a **data-driven, human-friendly narrative**, showing practical translation of numeric insights into communication.  

---

## ðŸ”¹ Task 7 â€“ Integration and Final Reflection

### Objective
Task 7 focuses on **transforming validated LLM outputs and prior analyses into a stakeholder-facing report** while documenting the workflow, reflecting on methodology, and considering ethical implications. The primary goal is to produce actionable recommendations for decision-makers (e.g., cricket coaches or team directors) based on IPL 2025 dataset insights, while emphasizing:

- **Reliability and reproducibility** of analysis  
- **Ethical and fairness considerations** in recommendations  
- **Transparency** of LLM-assisted outputs  

---

### Stakeholder & Decision Context
- **Stakeholders:** IPL team coaches, club directors, and performance analysts  
- **Decision Question:** Which players should the team prioritize for playoffs, which young talent to nurture, and how to strategize under pressure scenarios?  
- **Risk Levels:**  
  - **Low risk:** Operational recommendations such as minor lineup adjustments based on validated statistics.  
  - **Medium risk:** Investigatory actions like monitoring young bowlers or conducting controlled practice sessions.  
  - **High risk:** High-stakes decisions involving personnel changes or team restructuring.

By defining the decision context, the report ensures **recommendations are actionable, ethically sound, and aligned with stakeholdersâ€™ risk tolerance**.

---

### Data Provenance & Scope
- **Dataset:** IPL 2025 season statistics, including runs, strike rates, wickets, and overs.  
- **Source:** Publicly available cricket match records, scraped and processed locally.  
- **Collection:** Data collected using scripts (Task 4), validated for numeric accuracy via Pandas.  
- **Privacy Considerations:** Dataset contains only professional athlete performance statistics; no sensitive personal information included.  
- **Limitations:** Some interpretive questions (e.g., team-building under pressure) cannot be fully validated numerically. Observed differences between ChatGPT and DeepSeek responses highlight the need for **human validation**.

---

### Recreating & Validating Descriptive Results
- **Task 4 CSV Analyzer:** Unpacked nested data, calculated numeric summaries, and optionally aggregated metrics.  
- **Task 5 LLM Validation:** Compared ChatGPT and DeepSeek outputs against Pandas script results for Q1â€“Q6.  
- **Sanity Checks:**  
  - Verified numeric outputs matched script-calculated values.  
  - Checked for missing values, outliers, and inconsistent entries.  
  - Observed that LLM interpretations diverged for qualitative questions (team-building and playoff picks).

**Summary:** This step ensures **all numeric claims are reproducible** and the dataset is trustworthy for deriving recommendations.

---

### LLM Prompting & Transcript Capture
- **Prompts:** Natural language questions crafted around player statistics, performance under pressure, and strategic choices.  
- **Transcript Storage:** Full ChatGPT and DeepSeek outputs saved.  
- **Annotated Edits:** LLM outputs were reviewed; numeric data cross-verified, interpretive answers annotated for clarity.  

**Rationale:** Maintaining a transcript and annotation allows **future auditors to verify all LLM-assisted claims**, improving transparency.

---

### Quantifying Uncertainty
- Bootstrap estimates computed for strike rate distributions.  
- Confidence intervals calculated for average runs per batter to assess variability.  
- Observed that players like Nicholas Pooran and Noor Ahmad consistently performed in top percentiles, providing **moderate-to-high confidence** for stakeholder recommendations.

**Summary:** Quantifying uncertainty allows **risk-aware decisions**â€”stakeholders know which insights are robust versus subject to variability.

---

### Sanity Checks & Domain Validation
- Compared historical IPL data for consistency.  
- Checked batting averages and strike rates against official records.  
- Verified that LLM outputs did not hallucinate nonexistent player statistics.  

**Result:** Ensured **domain accuracy** and mitigated risk of false recommendations.

---

### Bias & Fairness Checks
- Evaluated under-representation of young bowlers versus experienced bowlers.  
- Checked that recommendations did not disproportionately favor certain player roles without statistical justification.  

**Outcome:** Bias minimized by grounding recommendations in numeric performance, ensuring fairness in team selection guidance.

---

### Robustness & Sensitivity
- Perturbation Tests: Removed top-performing players and re-ran aggregated statistics.  
- Observed that playoff recommendations largely aligned, indicating **robustness** of analysis.  
- Sensitivity Analysis: Adjusted strike rate thresholds to examine impact on player ranking. Results remained consistent, confirming reliability.

---

### Tiered Recommendations

**Operational (Low Risk)**
- Provide targeted coaching to Nicholas Pooran for high-pressure situations (based on top strike rate and runs consistency).  
- Monitor bowling workload of Mohammed Siraj to optimize performance during playoffs.  

**Investigatory (Medium Risk)**
- Conduct controlled training for Noor Ahmad to evaluate long-term potential and skill development.  
- Collect additional performance metrics for underrepresented young bowlers to refine selection decisions.

**High-Stakes (High Risk)**
- Consider strategic adjustments to team composition (e.g., substituting players in key matches) only after HR and coaching review.  
- Avoid relying solely on LLM interpretive suggestions for player selection.

---

### Ethical & Legal Considerations
- Recommendations **grounded in verified statistics** to avoid unjustified favoritism.  
- Decisions communicated transparently to team management to prevent misinterpretation of LLM-generated narratives.  
- No personal or sensitive data used, adhering to **data privacy standards**.  
- Acknowledged that **LLM outputs are advisory** and must not replace human judgment.

---

### Next Steps & Validation Plan
- Continue tracking player performance in upcoming matches and update the dataset for iterative analysis.  
- Periodically review LLM predictions versus real-world outcomes to evaluate **predictive validity**.  
- Maintain a version-controlled repository of scripts, prompts, and outputs for reproducibility.  

**Summary:** This plan ensures **continuous improvement and auditability** of decision-making recommendations.

---

### Summary of Task 7
Task 7 integrates prior research tasks into a **complete, stakeholder-ready analytics pipeline**:

- Verified dataset quality (Task 4)  
- Validated LLM insights (Task 5)  
- Generated narrative media representation (Task 6)  
- Documented process, uncertainty, and ethical considerations for **transparent, reproducible, and actionable decision-making**  

> Task 7 demonstrates a **full cycle from data ingestion to validated insights to ethically grounded recommendations**, suitable for professional cricket team decision-makers.


---

## ðŸ“‚ Appendices  

### Appendix A â€“ Key Task 4 Code Snippets  

```python
# Detect JSON-like columns
def detect_non_flat_columns(df):
    bad_cols = []
    for col in df.columns:
        if df[col].astype(str).str.contains(r'^\s*{.*}\s*$', na=False).any():
            bad_cols.append(col)
    return bad_cols

# Summarize numeric columns
def display_numeric_summary(df):
    numeric_df = df.select_dtypes(include='number')
    desc = numeric_df.describe().transpose()
    print(desc[['count', 'mean', 'min', 'max', 'std']])
## ðŸ“‚ Appendices

### Appendix B â€“ Task 5 LLM Outputs vs Script

| Q# | Question | ChatGPT | DeepSeek | Script |
|----|----------|---------|---------|--------|
| 1 | Highest Strike Rate (>500 runs) | Nicholas Pooran â€“ SR: 196.2, Runs: 524 | Nicholas Pooran â€“ SR: 196.25, Runs: 524 | 196.25 |
| 2 | Kohli vs Bumrah contributions | Kohli 657 runs, notes on Bumrahâ€™s clutch wickets | Kohli 657 > Bumrah 293.3 | 657 / 293.3 |
| 3 | Most overs bowled | Siraj â€“ 57 overs (342 balls) | Siraj â€“ 57 overs | 57 |
| 4 | Team-building under pressure | Pooran + Bumrah | Hardik Pandya | N/A |
| 5 | Playoff picks | Pooran, SKY, Iyer, Sudharsan, Klaasen; Noor, Bumrah, Hazlewood | Pooran, Gill, Iyer, Klaasen, SKY; Bumrah, Rashid, Noor | N/A |
| 6 | Young bowler potential | Noor Ahmad â€“ 24 wickets, SR 12.5 | Noor Ahmad â€“ 24 wickets, SR 12.5 | 24 / 12.5 |

---

### Appendix C â€“ Full Task 6 Interview Script

**[Reporter]:** Welcome, Sachin. Letâ€™s discuss standout performances in IPL 2025.  

**[Sachin Tendulkar]:** Thank you. Nicholas Pooranâ€™s batting was exceptional â€“ 524 runs with a strike rate of 196.25.  

**[Reporter]:** How do Kohliâ€™s batting and Bumrahâ€™s bowling compare?  

**[Sachin Tendulkar]:** Kohli contributed 657 runs, showing remarkable consistency. Bumrahâ€™s clutch wickets were pivotal in tight games.  

**[Reporter]:** Which young bowler impressed the most?  

**[Sachin Tendulkar]:** Noor Ahmad took 24 wickets with a strike rate of 12.5 â€“ a very promising talent.  

**[Reporter]:** Who would you build a playoff team around?  

**[Sachin Tendulkar]:** Pooran and Bumrah are core players; complementary all-rounders would round out the squad.  

**[Reporter]:** Thank you, Sachin. Any closing thoughts?  

**[Sachin Tendulkar]:** Consistency and adaptability are key. Teams that combine statistical insight with smart strategy will succeed.  

*(Full extended script includes all additional Q&A segments from Task 6.)*

---

### Task 5 â€“ Numeric Insights Summary

| Metric | Player | Value |
|--------|--------|-------|
| Highest Strike Rate (>500 runs) | Nicholas Pooran | 196.25 |
| Total Runs | Kohli | 657 |
| Bowler Contribution Score | Bumrah | 293.3 |
| Most Overs Bowled | Mohammed Siraj | 57 |
| Young Bowler Potential | Noor Ahmad | 24 wickets, SR 12.5 |

> This summary table provides a **visual snapshot** of numeric insights validated via Pandas script, highlighting key performers and actionable metrics.

---

## ðŸ“Š Final Conclusion

From raw CSV parsing to AI validation and narrative storytelling, this project demonstrates a **complete analytics lifecycle**:

- **Task 4 â†’** Structured data foundation  
- **Task 5 â†’** Validation of LLM insights  
- **Task 6 â†’** Stakeholder-ready narrative  
- **Task 7 â†’** Integration, reflection, and ethical documentation  

> Analytics is most impactful when **accurate, validated, and communicated clearly**.  

